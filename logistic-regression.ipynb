{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pandas\n",
    "products = pandas.read_csv(\"amazon_baby.csv\")  # read csv to pandas df\n",
    "products = products.fillna({'review':''})  # fill in N/A's in the review column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    import string\n",
    "    return text.translate(None, string.punctuation) \n",
    "\n",
    "products['review_clean'] = products.apply(lambda row: remove_punctuation(row['review']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "products = products[products['rating'] != 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_sentiment(rating):\n",
    "    return +1 if rating > 3 else -1\n",
    "\n",
    "products['sentiment'] = products.apply(lambda row : get_sentiment(row['rating']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get train data\n",
    "import json\n",
    "with open(\"module-2-assignment-train-idx.json\") as trainfile:\n",
    "    train_index = json.load(trainfile)\n",
    "train_data = products.iloc[train_index,:]\n",
    "\n",
    "# get test data\n",
    "with open(\"module-2-assignment-test-idx.json\") as testfile:\n",
    "    test_index = json.load(testfile)\n",
    "test_data = products.iloc[test_index,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(token_pattern=r'\\b\\w+\\b')\n",
    "# Use this token pattern to keep single-letter words\n",
    "# First, learn vocabulary from the training data and assign columns to words\n",
    "# Then convert the training data into a sparse matrix\n",
    "train_matrix = vectorizer.fit_transform(train_data['review_clean'])\n",
    "# Second, convert the test data into a sparse matrix, using the same word-column mapping\n",
    "test_matrix = vectorizer.transform(test_data['review_clean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "alg = LogisticRegression()\n",
    "sentiment_model = alg.fit(train_matrix, train_data['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121712\n",
      "85911\n"
     ]
    }
   ],
   "source": [
    "coeffs = sentiment_model.coef_[0]\n",
    "print(coeffs.size)\n",
    "print((coeffs >= 0).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolutely love it and all of the Scripture in it.  I purchased the Baby Boy version for my grandson when he was born and my daughter-in-law was thrilled to receive the same book again.\n",
      "\n",
      "\n",
      "Would not purchase again or recommend. The decals were thick almost plastic like and were coming off the wall as I was applying them! The would NOT stick! Literally stayed stuck for about 5 minutes then started peeling off.\n"
     ]
    }
   ],
   "source": [
    "sample_test_data = test_data[10:13]\n",
    "print(sample_test_data['review'].iloc[0])\n",
    "print(\"\\n\")\n",
    "print(sample_test_data['review'].iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  5.60798627  -3.1429946  -10.44043584]\n",
      "[1, -1, -1]\n"
     ]
    }
   ],
   "source": [
    "# predicting output using our sentiment model\n",
    "sample_test_matrix = vectorizer.transform(sample_test_data['review_clean'])\n",
    "scores = sentiment_model.decision_function(sample_test_matrix)\n",
    "print(scores)\n",
    "print([1 if i>=0 else -1 for i in scores])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1, -1, -1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prediction using predict function\n",
    "sentiment_model.predict(sample_test_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1  1]\n",
      "[[  3.65504085e-03   9.96344959e-01]\n",
      " [  9.58631800e-01   4.13681997e-02]\n",
      " [  9.99970774e-01   2.92256134e-05]]\n"
     ]
    }
   ],
   "source": [
    "# predicting probability of output using \n",
    "print(sentiment_model.classes_)\n",
    "print(sentiment_model.predict_proba(sample_test_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00365504085925\n",
      "0.996344959141\n",
      "[ 0.00365504  0.9586318   0.99997077]\n",
      "[  9.96344959e-01   4.13681997e-02   2.92256134e-05]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(1/(1+np.exp(5.60798627)))\n",
    "print(1/(1+np.exp(-5.60798627)))\n",
    "print(1/(1+np.exp(scores)))\n",
    "print(1/(1+np.exp(-1*scores)))\n",
    "# Last one has lowest probab to classify as +ve review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate probability for all test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.00000000e+00   1.00000000e+00   1.00000000e+00 ...,   8.27723545e-14\n",
      "   1.73290201e-15   8.93702816e-16]\n"
     ]
    }
   ],
   "source": [
    "test_matrix = vectorizer.transform(test_data['review_clean'])\n",
    "final_scores = sentiment_model.decision_function(test_matrix)\n",
    "final_probab_scores = 1/(1+np.exp(-1*final_scores))\n",
    "final_probab_scores.sort()\n",
    "print(final_probab_scores[::-1])\n",
    "# print(sorted_probab[0], sorted_probab[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      predictions                                               name\n",
      "20743           1  Fisher-Price Cradle 'N Swing,  My Little Snuga...\n",
      "30634           1  Graco FastAction Fold Jogger Click Connect Str...\n",
      "24899           1         Graco Pack 'n Play Element Playard - Flint\n",
      "21531           1  Roan Rocco Classic Pram Stroller 2-in-1 with B...\n",
      "17558           1  Freemie Hands-Free Concealable Breast Pump Col...\n",
      "25554           1         Diono RadianRXT Convertible Car Seat, Plum\n",
      "9555            1  Evenflo X Sport Plus Convenience Stroller - Ch...\n",
      "18112           1  Infantino Wrap and Tie Baby Carrier, Black Blu...\n",
      "9125            1         P'Kolino Silly Soft Seating in Tias, Green\n",
      "32782           1      Mamas &amp; Papas 2014 Urbo2 Stroller - Black\n",
      "26830           1  Baby Jogger City Mini GT Single Stroller, Shad...\n",
      "24286           1                  Britax 2012 B-Agile Stroller, Red\n",
      "30535           1  Buttons Cloth Diaper Cover - One Size - 8 Colo...\n",
      "11923           1       Evenflo 6 Pack Classic Glass Bottle, 4-Ounce\n",
      "15732           1    Baby Einstein Around The World Discovery Center\n",
      "14482           1  Simple Wishes Hands-Free Breastpump Bra, Pink,...\n",
      "4140            1     Britax Decathlon Convertible Car Seat, Tiffany\n",
      "30076           1  Ikea 36 Pcs Kalas Kids Plastic BPA Free Flatwa...\n",
      "33060           1  Summer Infant Wide View Digital Color Video Mo...\n",
      "26838           1  Baby Jogger City Mini GT Double Stroller, Shad...\n"
     ]
    }
   ],
   "source": [
    "predictions = sentiment_model.predict_proba(test_matrix)\n",
    "positive_predictions = predictions[:,1]\n",
    "positive_predictions_copy = positive_predictions\n",
    "products_name = test_data['name']\n",
    "predict_details = np.array([positive_predictions, products_name]).T\n",
    "df = pandas.DataFrame(predict_details)\n",
    "df.columns = ['predictions', 'name']\n",
    "df = df.sort_values(by=['predictions'], ascending=[False])\n",
    "print(df.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictions</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5831</th>\n",
       "      <td>1.6146e-09</td>\n",
       "      <td>Regalo My Cot Portable Bed, Royal Blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15062</th>\n",
       "      <td>1.49428e-09</td>\n",
       "      <td>Thirsties Hemp Inserts 2 Pack, Small 6-18 Lbs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>1.10018e-09</td>\n",
       "      <td>Safety 1st Deluxe 4-in-1 Bath Station</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28120</th>\n",
       "      <td>8.2667e-10</td>\n",
       "      <td>VTech Communications Safe &amp;amp; Sound Digital ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27231</th>\n",
       "      <td>7.09893e-10</td>\n",
       "      <td>NUK Cook-n-Blend Baby Food Maker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7310</th>\n",
       "      <td>6.50982e-10</td>\n",
       "      <td>Chicco Cortina KeyFit 30 Travel System in Adve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31226</th>\n",
       "      <td>6.17932e-10</td>\n",
       "      <td>Belkin WeMo Wi-Fi Baby Monitor for Apple iPhon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13751</th>\n",
       "      <td>6.05155e-10</td>\n",
       "      <td>Peg-Perego Tatamia High Chair, White Latte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10814</th>\n",
       "      <td>4.57446e-10</td>\n",
       "      <td>Ellaroo Mei Tai Baby Carrier - Hershey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1810</th>\n",
       "      <td>4.42926e-10</td>\n",
       "      <td>Cosco Alpha Omega Elite Convertible Car Seat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1942</th>\n",
       "      <td>1.03471e-10</td>\n",
       "      <td>Philips AVENT Newborn Starter Set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20594</th>\n",
       "      <td>8.93475e-11</td>\n",
       "      <td>Motorola Digital Video Baby Monitor with Room ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14711</th>\n",
       "      <td>3.73805e-11</td>\n",
       "      <td>Cloth Diaper Sprayer--styles may vary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9655</th>\n",
       "      <td>3.18258e-11</td>\n",
       "      <td>Safety 1st High-Def Digital Monitor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17069</th>\n",
       "      <td>4.02865e-13</td>\n",
       "      <td>The First Years True Choice P400 Premium Digit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28184</th>\n",
       "      <td>1.7757e-13</td>\n",
       "      <td>VTech Communications Safe &amp;amp; Sounds Full Co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8818</th>\n",
       "      <td>1.31394e-13</td>\n",
       "      <td>Adiri BPA Free Natural Nurser Ultimate Bottle ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13939</th>\n",
       "      <td>8.27724e-14</td>\n",
       "      <td>Safety 1st Exchangeable Tip 3 in 1 Thermometer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21700</th>\n",
       "      <td>1.7329e-15</td>\n",
       "      <td>Levana Safe N'See Digital Video Baby Monitor w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2931</th>\n",
       "      <td>8.93703e-16</td>\n",
       "      <td>Fisher-Price Ocean Wonders Aquarium Bouncer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       predictions                                               name\n",
       "5831    1.6146e-09             Regalo My Cot Portable Bed, Royal Blue\n",
       "15062  1.49428e-09      Thirsties Hemp Inserts 2 Pack, Small 6-18 Lbs\n",
       "205    1.10018e-09              Safety 1st Deluxe 4-in-1 Bath Station\n",
       "28120   8.2667e-10  VTech Communications Safe &amp; Sound Digital ...\n",
       "27231  7.09893e-10                   NUK Cook-n-Blend Baby Food Maker\n",
       "7310   6.50982e-10  Chicco Cortina KeyFit 30 Travel System in Adve...\n",
       "31226  6.17932e-10  Belkin WeMo Wi-Fi Baby Monitor for Apple iPhon...\n",
       "13751  6.05155e-10         Peg-Perego Tatamia High Chair, White Latte\n",
       "10814  4.57446e-10             Ellaroo Mei Tai Baby Carrier - Hershey\n",
       "1810   4.42926e-10       Cosco Alpha Omega Elite Convertible Car Seat\n",
       "1942   1.03471e-10                  Philips AVENT Newborn Starter Set\n",
       "20594  8.93475e-11  Motorola Digital Video Baby Monitor with Room ...\n",
       "14711  3.73805e-11              Cloth Diaper Sprayer--styles may vary\n",
       "9655   3.18258e-11                Safety 1st High-Def Digital Monitor\n",
       "17069  4.02865e-13  The First Years True Choice P400 Premium Digit...\n",
       "28184   1.7757e-13  VTech Communications Safe &amp; Sounds Full Co...\n",
       "8818   1.31394e-13  Adiri BPA Free Natural Nurser Ultimate Bottle ...\n",
       "13939  8.27724e-14     Safety 1st Exchangeable Tip 3 in 1 Thermometer\n",
       "21700   1.7329e-15  Levana Safe N'See Digital Video Baby Monitor w...\n",
       "2931   8.93703e-16        Fisher-Price Ocean Wonders Aquarium Bouncer"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute accuracy of classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.932235421166\n"
     ]
    }
   ],
   "source": [
    "predictions = sentiment_model.predict(test_matrix)\n",
    "accuracy = len(test_data[test_data['sentiment'] == predictions])/float(len(predictions))\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Another classifier with fewer words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "significant_words = ['love', 'great', 'easy', 'old', 'little', 'perfect', 'loves', \n",
    "      'well', 'able', 'car', 'broke', 'less', 'even', 'waste', 'disappointed', \n",
    "      'work', 'product', 'money', 'would', 'return']\n",
    "vectorizer_word_subset = CountVectorizer(vocabulary=significant_words) # limit to 20 words\n",
    "train_matrix_word_subset = vectorizer_word_subset.fit_transform(train_data['review_clean'])\n",
    "test_matrix_word_subset = vectorizer_word_subset.transform(test_data['review_clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alg2 = LogisticRegression()\n",
    "simple_model = alg2.fit(train_matrix_word_subset, train_data['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "simple_model_coef_table = pandas.DataFrame({'word':significant_words,\n",
    "                                         'coefficient':simple_model.coef_.flatten()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefficient</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.673074</td>\n",
       "      <td>loves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.509812</td>\n",
       "      <td>perfect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.363690</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.192538</td>\n",
       "      <td>easy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.944000</td>\n",
       "      <td>great</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.520186</td>\n",
       "      <td>little</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.503760</td>\n",
       "      <td>well</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.190909</td>\n",
       "      <td>able</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.085513</td>\n",
       "      <td>old</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.058855</td>\n",
       "      <td>car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.209563</td>\n",
       "      <td>less</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.320556</td>\n",
       "      <td>product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.362167</td>\n",
       "      <td>would</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.511380</td>\n",
       "      <td>even</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.621169</td>\n",
       "      <td>work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.898031</td>\n",
       "      <td>money</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-1.651576</td>\n",
       "      <td>broke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-2.033699</td>\n",
       "      <td>waste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-2.109331</td>\n",
       "      <td>return</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-2.348298</td>\n",
       "      <td>disappointed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    coefficient          word\n",
       "6      1.673074         loves\n",
       "5      1.509812       perfect\n",
       "0      1.363690          love\n",
       "2      1.192538          easy\n",
       "1      0.944000         great\n",
       "4      0.520186        little\n",
       "7      0.503760          well\n",
       "8      0.190909          able\n",
       "3      0.085513           old\n",
       "9      0.058855           car\n",
       "11    -0.209563          less\n",
       "16    -0.320556       product\n",
       "18    -0.362167         would\n",
       "12    -0.511380          even\n",
       "15    -0.621169          work\n",
       "17    -0.898031         money\n",
       "10    -1.651576         broke\n",
       "13    -2.033699         waste\n",
       "19    -2.109331        return\n",
       "14    -2.348298  disappointed"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_model_coef_table.sort_values(by=['coefficient'], ascending=[False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -1.23889324e+00,   1.59863291e-04,   2.63828080e-02, ...,\n",
       "         1.17685365e-02,   3.10346626e-03,  -6.36644403e-05])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_model.coef_.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Comparing Sentiment Model and Simple Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.96800233855\n"
     ]
    }
   ],
   "source": [
    "# accuracy of sentiment model on train data\n",
    "predictions = sentiment_model.predict(train_matrix)\n",
    "accuracy = len(train_data[train_data['sentiment'] == predictions])/float(len(predictions))\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.866822570007\n"
     ]
    }
   ],
   "source": [
    "# accuracy of simple model on train data\n",
    "predictions = simple_model.predict(train_matrix_word_subset)\n",
    "accuracy = len(train_data[train_data['sentiment'] == predictions])/float(len(predictions))\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.932235421166\n"
     ]
    }
   ],
   "source": [
    "# accuracy of sentiment model on test data\n",
    "predictions = sentiment_model.predict(test_matrix)\n",
    "accuracy = len(test_data[test_data['sentiment'] == predictions])/float(len(predictions))\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.869360451164\n"
     ]
    }
   ],
   "source": [
    "# accuracy of simple model on test data\n",
    "predictions = simple_model.predict(test_matrix_word_subset)\n",
    "accuracy = len(test_data[test_data['sentiment'] == predictions])/float(len(predictions))\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.842782577394\n"
     ]
    }
   ],
   "source": [
    "# accuracy of majority class classifier for test data\n",
    "accuracy = len(test_data[test_data['sentiment'] == 1])/float(len(predictions))\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
