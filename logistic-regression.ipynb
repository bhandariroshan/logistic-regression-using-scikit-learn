{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Implementation Using pandas and scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Planetwise Flannel Wipes</td>\n",
       "      <td>These flannel wipes are OK, but in my opinion ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Planetwise Wipe Pouch</td>\n",
       "      <td>it came early and was not disappointed. i love...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annas Dream Full Quilt with 2 Shams</td>\n",
       "      <td>Very soft and comfortable and warmer than it l...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>This is a product well worth the purchase.  I ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>All of my kids have cried non-stop when I trie...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0                           Planetwise Flannel Wipes   \n",
       "1                              Planetwise Wipe Pouch   \n",
       "2                Annas Dream Full Quilt with 2 Shams   \n",
       "3  Stop Pacifier Sucking without tears with Thumb...   \n",
       "4  Stop Pacifier Sucking without tears with Thumb...   \n",
       "\n",
       "                                              review  rating  \n",
       "0  These flannel wipes are OK, but in my opinion ...       3  \n",
       "1  it came early and was not disappointed. i love...       5  \n",
       "2  Very soft and comfortable and warmer than it l...       5  \n",
       "3  This is a product well worth the purchase.  I ...       5  \n",
       "4  All of my kids have cried non-stop when I trie...       5  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pandas\n",
    "products = pandas.read_csv(\"amazon_baby.csv\")  # read csv to pandas df\n",
    "products = products.fillna({'review':''})  # fill in N/A's in the review column\n",
    "products.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Planetwise Flannel Wipes</td>\n",
       "      <td>These flannel wipes are OK, but in my opinion ...</td>\n",
       "      <td>3</td>\n",
       "      <td>These flannel wipes are OK but in my opinion n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Planetwise Wipe Pouch</td>\n",
       "      <td>it came early and was not disappointed. i love...</td>\n",
       "      <td>5</td>\n",
       "      <td>it came early and was not disappointed i love ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annas Dream Full Quilt with 2 Shams</td>\n",
       "      <td>Very soft and comfortable and warmer than it l...</td>\n",
       "      <td>5</td>\n",
       "      <td>Very soft and comfortable and warmer than it l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>This is a product well worth the purchase.  I ...</td>\n",
       "      <td>5</td>\n",
       "      <td>This is a product well worth the purchase  I h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>All of my kids have cried non-stop when I trie...</td>\n",
       "      <td>5</td>\n",
       "      <td>All of my kids have cried nonstop when I tried...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0                           Planetwise Flannel Wipes   \n",
       "1                              Planetwise Wipe Pouch   \n",
       "2                Annas Dream Full Quilt with 2 Shams   \n",
       "3  Stop Pacifier Sucking without tears with Thumb...   \n",
       "4  Stop Pacifier Sucking without tears with Thumb...   \n",
       "\n",
       "                                              review  rating  \\\n",
       "0  These flannel wipes are OK, but in my opinion ...       3   \n",
       "1  it came early and was not disappointed. i love...       5   \n",
       "2  Very soft and comfortable and warmer than it l...       5   \n",
       "3  This is a product well worth the purchase.  I ...       5   \n",
       "4  All of my kids have cried non-stop when I trie...       5   \n",
       "\n",
       "                                        review_clean  \n",
       "0  These flannel wipes are OK but in my opinion n...  \n",
       "1  it came early and was not disappointed i love ...  \n",
       "2  Very soft and comfortable and warmer than it l...  \n",
       "3  This is a product well worth the purchase  I h...  \n",
       "4  All of my kids have cried nonstop when I tried...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a simple method to remove punctuation from review text\n",
    "def remove_punctuation(text):\n",
    "    import string\n",
    "    return text.translate(None, string.punctuation) \n",
    "\n",
    "# apply the remove_punctuation method on the review column and save to a new review_clean column\n",
    "products['review_clean'] = products.apply(lambda row: remove_punctuation(row['review']), axis=1)\n",
    "products.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# since 3 star ratings are neutral, ignore them.\n",
    "products = products[products['rating'] != 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_clean</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Planetwise Wipe Pouch</td>\n",
       "      <td>it came early and was not disappointed. i love...</td>\n",
       "      <td>5</td>\n",
       "      <td>it came early and was not disappointed i love ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annas Dream Full Quilt with 2 Shams</td>\n",
       "      <td>Very soft and comfortable and warmer than it l...</td>\n",
       "      <td>5</td>\n",
       "      <td>Very soft and comfortable and warmer than it l...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>This is a product well worth the purchase.  I ...</td>\n",
       "      <td>5</td>\n",
       "      <td>This is a product well worth the purchase  I h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>All of my kids have cried non-stop when I trie...</td>\n",
       "      <td>5</td>\n",
       "      <td>All of my kids have cried nonstop when I tried...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>When the Binky Fairy came to our house, we did...</td>\n",
       "      <td>5</td>\n",
       "      <td>When the Binky Fairy came to our house we didn...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "1                              Planetwise Wipe Pouch   \n",
       "2                Annas Dream Full Quilt with 2 Shams   \n",
       "3  Stop Pacifier Sucking without tears with Thumb...   \n",
       "4  Stop Pacifier Sucking without tears with Thumb...   \n",
       "5  Stop Pacifier Sucking without tears with Thumb...   \n",
       "\n",
       "                                              review  rating  \\\n",
       "1  it came early and was not disappointed. i love...       5   \n",
       "2  Very soft and comfortable and warmer than it l...       5   \n",
       "3  This is a product well worth the purchase.  I ...       5   \n",
       "4  All of my kids have cried non-stop when I trie...       5   \n",
       "5  When the Binky Fairy came to our house, we did...       5   \n",
       "\n",
       "                                        review_clean  sentiment  \n",
       "1  it came early and was not disappointed i love ...          1  \n",
       "2  Very soft and comfortable and warmer than it l...          1  \n",
       "3  This is a product well worth the purchase  I h...          1  \n",
       "4  All of my kids have cried nonstop when I tried...          1  \n",
       "5  When the Binky Fairy came to our house we didn...          1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a simple function to get positive or negative sentiment based on rating\n",
    "def get_sentiment(rating):\n",
    "    return +1 if rating > 3 else -1\n",
    "\n",
    "# apply the get_sentiment method on the rating column and save to a new sentiment column\n",
    "products['sentiment'] = products.apply(lambda row : get_sentiment(row['rating']), axis=1)\n",
    "products.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get train data\n",
    "import json\n",
    "# load the train data ids from json file\n",
    "with open(\"train-idx.json\") as trainfile:\n",
    "    train_index = json.load(trainfile)\n",
    "# select training data using the train ids\n",
    "train_data = products.iloc[train_index,:]\n",
    "\n",
    "# get test data\n",
    "with open(\"test-idx.json\") as testfile:\n",
    "    test_index = json.load(testfile)\n",
    "test_data = products.iloc[test_index,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(token_pattern=r'\\b\\w+\\b')\n",
    "# Use this token pattern to keep single-letter words\n",
    "# First, learn vocabulary from the training data and assign columns to words\n",
    "# Then convert the training data into a sparse matrix\n",
    "train_matrix = vectorizer.fit_transform(train_data['review_clean'])\n",
    "# Second, convert the test data into a sparse matrix, using the same word-column mapping\n",
    "test_matrix = vectorizer.transform(test_data['review_clean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "alg = LogisticRegression()\n",
    "# train the logistic regression algorithm using train matrix and sentiment output\n",
    "sentiment_model = alg.fit(train_matrix, train_data['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Coefficients Length', 121712)\n",
      "('Positive Coefficients', 85911)\n"
     ]
    }
   ],
   "source": [
    "coeffs = sentiment_model.coef_[0]\n",
    "print('Coefficients Length', coeffs.size)\n",
    "print('Positive Coefficients', (coeffs >= 0).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('First sample test data review \\n', 'Absolutely love it and all of the Scripture in it.  I purchased the Baby Boy version for my grandson when he was born and my daughter-in-law was thrilled to receive the same book again.')\n",
      "\n",
      "\n",
      "('Second sample test data review', 'Would not purchase again or recommend. The decals were thick almost plastic like and were coming off the wall as I was applying them! The would NOT stick! Literally stayed stuck for about 5 minutes then started peeling off.')\n"
     ]
    }
   ],
   "source": [
    "# inspecting a few test data samples\n",
    "sample_test_data = test_data[10:13]\n",
    "print('First sample test data review \\n', sample_test_data['review'].iloc[0])\n",
    "print(\"\\n\")\n",
    "print('Second sample test data review', sample_test_data['review'].iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('scores', array([  5.60798627,  -3.1429946 , -10.44043584]))\n",
      "[1, -1, -1]\n"
     ]
    }
   ],
   "source": [
    "# predicting output using our sentiment model\n",
    "sample_test_matrix = vectorizer.transform(sample_test_data['review_clean'])\n",
    "scores = sentiment_model.decision_function(sample_test_matrix)\n",
    "print('scores', scores)\n",
    "print([1 if i>=0 else -1 for i in scores])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1, -1, -1])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prediction using predict function\n",
    "sentiment_model.predict(sample_test_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1  1]\n",
      "[[  3.65504085e-03   9.96344959e-01]\n",
      " [  9.58631800e-01   4.13681997e-02]\n",
      " [  9.99970774e-01   2.92256134e-05]]\n"
     ]
    }
   ],
   "source": [
    "# predicting probability of output using \n",
    "print(sentiment_model.classes_)\n",
    "print(sentiment_model.predict_proba(sample_test_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  9.96344959e-01   4.13681997e-02   2.92256134e-05]\n"
     ]
    }
   ],
   "source": [
    "# using numpy to calculate the probabilistic score for classifier\n",
    "import numpy as np\n",
    "print(1/(1+np.exp(-1*scores)))\n",
    "# Last one has lowest probab to classify as +ve review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate probability for all test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.00000000e+00   1.00000000e+00   1.00000000e+00 ...,   8.27723545e-14\n",
      "   1.73290201e-15   8.93702816e-16]\n"
     ]
    }
   ],
   "source": [
    "# get test matrix for all test data\n",
    "test_matrix = vectorizer.transform(test_data['review_clean'])\n",
    "final_scores = sentiment_model.decision_function(test_matrix)\n",
    "final_probab_scores = 1/(1+np.exp(-1*final_scores))\n",
    "final_probab_scores.sort()\n",
    "print(final_probab_scores[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      predictions                                               name\n",
      "20743           1  Fisher-Price Cradle 'N Swing,  My Little Snuga...\n",
      "30634           1  Graco FastAction Fold Jogger Click Connect Str...\n",
      "24899           1         Graco Pack 'n Play Element Playard - Flint\n",
      "21531           1  Roan Rocco Classic Pram Stroller 2-in-1 with B...\n",
      "17558           1  Freemie Hands-Free Concealable Breast Pump Col...\n",
      "25554           1         Diono RadianRXT Convertible Car Seat, Plum\n",
      "9555            1  Evenflo X Sport Plus Convenience Stroller - Ch...\n",
      "18112           1  Infantino Wrap and Tie Baby Carrier, Black Blu...\n",
      "9125            1         P'Kolino Silly Soft Seating in Tias, Green\n",
      "32782           1      Mamas &amp; Papas 2014 Urbo2 Stroller - Black\n",
      "26830           1  Baby Jogger City Mini GT Single Stroller, Shad...\n",
      "24286           1                  Britax 2012 B-Agile Stroller, Red\n",
      "30535           1  Buttons Cloth Diaper Cover - One Size - 8 Colo...\n",
      "11923           1       Evenflo 6 Pack Classic Glass Bottle, 4-Ounce\n",
      "15732           1    Baby Einstein Around The World Discovery Center\n",
      "14482           1  Simple Wishes Hands-Free Breastpump Bra, Pink,...\n",
      "4140            1     Britax Decathlon Convertible Car Seat, Tiffany\n",
      "30076           1  Ikea 36 Pcs Kalas Kids Plastic BPA Free Flatwa...\n",
      "33060           1  Summer Infant Wide View Digital Color Video Mo...\n",
      "26838           1  Baby Jogger City Mini GT Double Stroller, Shad...\n"
     ]
    }
   ],
   "source": [
    "# using predict_proba function of scikit learn to get probabilistic scores for classifier\n",
    "predictions = sentiment_model.predict_proba(test_matrix)\n",
    "positive_predictions = predictions[:,1]\n",
    "\n",
    "# create a data frame in python to hold product name and probability value\n",
    "positive_predictions_copy = positive_predictions\n",
    "products_name = test_data['name']\n",
    "predict_details = np.array([positive_predictions, products_name]).T\n",
    "df = pandas.DataFrame(predict_details)\n",
    "df.columns = ['predictions', 'name']\n",
    "\n",
    "# sort df to get 20 most positive reviews\n",
    "df = df.sort_values(by=['predictions'], ascending=[False])\n",
    "print(df.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictions</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5831</th>\n",
       "      <td>1.6146e-09</td>\n",
       "      <td>Regalo My Cot Portable Bed, Royal Blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15062</th>\n",
       "      <td>1.49428e-09</td>\n",
       "      <td>Thirsties Hemp Inserts 2 Pack, Small 6-18 Lbs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>1.10018e-09</td>\n",
       "      <td>Safety 1st Deluxe 4-in-1 Bath Station</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28120</th>\n",
       "      <td>8.2667e-10</td>\n",
       "      <td>VTech Communications Safe &amp;amp; Sound Digital ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27231</th>\n",
       "      <td>7.09893e-10</td>\n",
       "      <td>NUK Cook-n-Blend Baby Food Maker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7310</th>\n",
       "      <td>6.50982e-10</td>\n",
       "      <td>Chicco Cortina KeyFit 30 Travel System in Adve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31226</th>\n",
       "      <td>6.17932e-10</td>\n",
       "      <td>Belkin WeMo Wi-Fi Baby Monitor for Apple iPhon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13751</th>\n",
       "      <td>6.05155e-10</td>\n",
       "      <td>Peg-Perego Tatamia High Chair, White Latte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10814</th>\n",
       "      <td>4.57446e-10</td>\n",
       "      <td>Ellaroo Mei Tai Baby Carrier - Hershey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1810</th>\n",
       "      <td>4.42926e-10</td>\n",
       "      <td>Cosco Alpha Omega Elite Convertible Car Seat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1942</th>\n",
       "      <td>1.03471e-10</td>\n",
       "      <td>Philips AVENT Newborn Starter Set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20594</th>\n",
       "      <td>8.93475e-11</td>\n",
       "      <td>Motorola Digital Video Baby Monitor with Room ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14711</th>\n",
       "      <td>3.73805e-11</td>\n",
       "      <td>Cloth Diaper Sprayer--styles may vary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9655</th>\n",
       "      <td>3.18258e-11</td>\n",
       "      <td>Safety 1st High-Def Digital Monitor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17069</th>\n",
       "      <td>4.02865e-13</td>\n",
       "      <td>The First Years True Choice P400 Premium Digit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28184</th>\n",
       "      <td>1.7757e-13</td>\n",
       "      <td>VTech Communications Safe &amp;amp; Sounds Full Co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8818</th>\n",
       "      <td>1.31394e-13</td>\n",
       "      <td>Adiri BPA Free Natural Nurser Ultimate Bottle ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13939</th>\n",
       "      <td>8.27724e-14</td>\n",
       "      <td>Safety 1st Exchangeable Tip 3 in 1 Thermometer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21700</th>\n",
       "      <td>1.7329e-15</td>\n",
       "      <td>Levana Safe N'See Digital Video Baby Monitor w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2931</th>\n",
       "      <td>8.93703e-16</td>\n",
       "      <td>Fisher-Price Ocean Wonders Aquarium Bouncer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       predictions                                               name\n",
       "5831    1.6146e-09             Regalo My Cot Portable Bed, Royal Blue\n",
       "15062  1.49428e-09      Thirsties Hemp Inserts 2 Pack, Small 6-18 Lbs\n",
       "205    1.10018e-09              Safety 1st Deluxe 4-in-1 Bath Station\n",
       "28120   8.2667e-10  VTech Communications Safe &amp; Sound Digital ...\n",
       "27231  7.09893e-10                   NUK Cook-n-Blend Baby Food Maker\n",
       "7310   6.50982e-10  Chicco Cortina KeyFit 30 Travel System in Adve...\n",
       "31226  6.17932e-10  Belkin WeMo Wi-Fi Baby Monitor for Apple iPhon...\n",
       "13751  6.05155e-10         Peg-Perego Tatamia High Chair, White Latte\n",
       "10814  4.57446e-10             Ellaroo Mei Tai Baby Carrier - Hershey\n",
       "1810   4.42926e-10       Cosco Alpha Omega Elite Convertible Car Seat\n",
       "1942   1.03471e-10                  Philips AVENT Newborn Starter Set\n",
       "20594  8.93475e-11  Motorola Digital Video Baby Monitor with Room ...\n",
       "14711  3.73805e-11              Cloth Diaper Sprayer--styles may vary\n",
       "9655   3.18258e-11                Safety 1st High-Def Digital Monitor\n",
       "17069  4.02865e-13  The First Years True Choice P400 Premium Digit...\n",
       "28184   1.7757e-13  VTech Communications Safe &amp; Sounds Full Co...\n",
       "8818   1.31394e-13  Adiri BPA Free Natural Nurser Ultimate Bottle ...\n",
       "13939  8.27724e-14     Safety 1st Exchangeable Tip 3 in 1 Thermometer\n",
       "21700   1.7329e-15  Levana Safe N'See Digital Video Baby Monitor w...\n",
       "2931   8.93703e-16        Fisher-Price Ocean Wonders Aquarium Bouncer"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get 20 most negative reviewed products\n",
    "df.tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute accuracy of classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Sentiment Model accuracy is', 0.9322354211663066)\n"
     ]
    }
   ],
   "source": [
    "predictions = sentiment_model.predict(test_matrix)\n",
    "accuracy = len(test_data[test_data['sentiment'] == predictions])/float(len(predictions))\n",
    "print('Sentiment Model accuracy is', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Another classifier with fewer words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "significant_words = ['love', 'great', 'easy', 'old', 'little', 'perfect', 'loves', \n",
    "      'well', 'able', 'car', 'broke', 'less', 'even', 'waste', 'disappointed', \n",
    "      'work', 'product', 'money', 'would', 'return']\n",
    "vectorizer_word_subset = CountVectorizer(vocabulary=significant_words) # limit to 20 words\n",
    "train_matrix_word_subset = vectorizer_word_subset.fit_transform(train_data['review_clean'])\n",
    "test_matrix_word_subset = vectorizer_word_subset.transform(test_data['review_clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit a different model using the train matrix for fixed words and train output\n",
    "alg2 = LogisticRegression()\n",
    "simple_model = alg2.fit(train_matrix_word_subset, train_data['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a dataframe to store words and their coefficients\n",
    "simple_model_coef_table = pandas.DataFrame({'word':significant_words,\n",
    "                                         'coefficient':simple_model.coef_.flatten()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefficient</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.673074</td>\n",
       "      <td>loves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.509812</td>\n",
       "      <td>perfect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.363690</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.192538</td>\n",
       "      <td>easy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.944000</td>\n",
       "      <td>great</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.520186</td>\n",
       "      <td>little</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.503760</td>\n",
       "      <td>well</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.190909</td>\n",
       "      <td>able</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.085513</td>\n",
       "      <td>old</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.058855</td>\n",
       "      <td>car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.209563</td>\n",
       "      <td>less</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.320556</td>\n",
       "      <td>product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.362167</td>\n",
       "      <td>would</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.511380</td>\n",
       "      <td>even</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.621169</td>\n",
       "      <td>work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.898031</td>\n",
       "      <td>money</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-1.651576</td>\n",
       "      <td>broke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-2.033699</td>\n",
       "      <td>waste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-2.109331</td>\n",
       "      <td>return</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-2.348298</td>\n",
       "      <td>disappointed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    coefficient          word\n",
       "6      1.673074         loves\n",
       "5      1.509812       perfect\n",
       "0      1.363690          love\n",
       "2      1.192538          easy\n",
       "1      0.944000         great\n",
       "4      0.520186        little\n",
       "7      0.503760          well\n",
       "8      0.190909          able\n",
       "3      0.085513           old\n",
       "9      0.058855           car\n",
       "11    -0.209563          less\n",
       "16    -0.320556       product\n",
       "18    -0.362167         would\n",
       "12    -0.511380          even\n",
       "15    -0.621169          work\n",
       "17    -0.898031         money\n",
       "10    -1.651576         broke\n",
       "13    -2.033699         waste\n",
       "19    -2.109331        return\n",
       "14    -2.348298  disappointed"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get most positive words by sorting\n",
    "simple_model_coef_table.sort_values(by=['coefficient'], ascending=[False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -1.23889324e+00,   1.59863291e-04,   2.63828080e-02, ...,\n",
       "         1.17685365e-02,   3.10346626e-03,  -6.36644403e-05])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_model.coef_.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Comparing Sentiment Model and Simple Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.96800233855\n"
     ]
    }
   ],
   "source": [
    "# accuracy of sentiment model on train data\n",
    "predictions = sentiment_model.predict(train_matrix)\n",
    "accuracy = len(train_data[train_data['sentiment'] == predictions])/float(len(predictions))\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.866822570007\n"
     ]
    }
   ],
   "source": [
    "# accuracy of simple model on train data\n",
    "predictions = simple_model.predict(train_matrix_word_subset)\n",
    "accuracy = len(train_data[train_data['sentiment'] == predictions])/float(len(predictions))\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.932235421166\n"
     ]
    }
   ],
   "source": [
    "# accuracy of sentiment model on test data\n",
    "predictions = sentiment_model.predict(test_matrix)\n",
    "accuracy = len(test_data[test_data['sentiment'] == predictions])/float(len(predictions))\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.869360451164\n"
     ]
    }
   ],
   "source": [
    "# accuracy of simple model on test data\n",
    "predictions = simple_model.predict(test_matrix_word_subset)\n",
    "accuracy = len(test_data[test_data['sentiment'] == predictions])/float(len(predictions))\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.842782577394\n"
     ]
    }
   ],
   "source": [
    "# accuracy of majority class classifier for test data\n",
    "accuracy = len(test_data[test_data['sentiment'] == 1])/float(len(predictions))\n",
    "print(accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
